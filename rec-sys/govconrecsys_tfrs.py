# -*- coding: utf-8 -*-
"""govConRecSys_TFRS

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1YnmgDlEf7aR0PYYZ5w_ynNTh4MvdIMl7
"""

!pip install tensorflow_recommenders

!pip install transformers

from typing import Dict, Text
import pandas as pd
import tensorflow as tf
import tensorflow_recommenders as tfrs
from tensorflow.keras.layers.experimental.preprocessing import StringLookup
from transformers import TFBertModel, BertTokenizer

dataframe = pd.read_csv('/content/drive/MyDrive/db/govConRecSys_FakeTrainD_1.csv')

# Instantiate BERT model and tokenizer for text encoding
bert_tokenizer = BertTokenizer.from_pretrained("bert-base-uncased")
bert_model = TFBertModel.from_pretrained("bert-base-uncased")

# Custom BERT text encoding layer
class BertTextEncoder(tf.keras.layers.Layer):
    def __init__(self, bert_model, tokenizer, **kwargs):
        super().__init__(**kwargs)
        self.bert_model = bert_model
        self.tokenizer = tokenizer

    def call(self, text):
        inputs = self.tokenizer(text, return_tensors="tf", padding=True, truncation=True, max_length=512)
        outputs = self.bert_model(inputs)
        return outputs["last_hidden_state"][:,0,:]

# Instantiate the custom BERT text encoder
bert_text_encoder = BertTextEncoder(bert_model, bert_tokenizer)

# Preprocess the categorical features using StringLookup
categorical_columns_receiver = ["reciever_country_name", "reciever_state_name"]
categorical_columns_business = ["awarding_agency_name", "client_office_name", "location", "award_type", "type_of_business"]

# Adapt StringLookup layers for receiver features
categorical_encoders_receiver = {}
for column in categorical_columns_receiver:
    encoder = StringLookup(output_mode="int")
    encoder.adapt(dataframe[column])
    categorical_encoders_receiver[column] = encoder

# Adapt StringLookup layers for business features
categorical_encoders_business = {}
for column in categorical_columns_business:
    encoder = StringLookup(output_mode="int")
    encoder.adapt(dataframe[column])
    categorical_encoders_business[column] = encoder

def encode_text_with_bert(text_series, bert_text_encoder):
    # Convert the pandas series to a list
    text_list = text_series.tolist()
    # Use the BertTextEncoder to encode the text
    return bert_text_encoder(text_list)

# Encode 'product_description' and 'service_description' columns
product_descriptions_encoded = encode_text_with_bert(dataframe["product_description"], bert_text_encoder)
service_descriptions_encoded = encode_text_with_bert(dataframe["service_description"], bert_text_encoder)

# Encode text features
#profile_descriptions_encoded = encode_text(dataframe["profile_description"])
#business_data_encoded = encode_text(dataframe["business_data"])

class ReceiverModel(tf.keras.Model):
    def __init__(self, categorical_encoders):
        super().__init__()
        self.embedding_layers = {
            column: tf.keras.layers.Embedding(input_dim=encoder.vocab_size(), output_dim=32)
            for column, encoder in categorical_encoders.items()
        }

    def call(self, inputs):
        return tf.concat([self.embedding_layers[column](inputs[column])
                          for column in self.embedding_layers], axis=1)
class BusinessModel(tf.keras.Model):
    def __init__(self, categorical_encoders, product_description_embedding, service_description_embedding):
        super().__init__()
        self.embedding_layers = {
            column: tf.keras.layers.Embedding(input_dim=encoder.vocab_size(), output_dim=64)
            for column, encoder in categorical_encoders.items()
        }
        self.product_description_embedding = product_description_embedding
        self.service_description_embedding = service_description_embedding

    def call(self, inputs):
        categorical_embeddings = tf.concat([self.embedding_layers[column](inputs[column])
                                            for column in self.embedding_layers], axis=1)
        return tf.concat([categorical_embeddings, self.product_description_embedding, self.service_description_embedding], axis=1)

class RecommenderModel(tfrs.Model):
    def __init__(self, receiver_model, business_model, task):
        super().__init__()
        self.receiver_model = receiver_model
        self.business_model = business_model
        self.task = task

    def compute_loss(self, features, training=False):
        receiver_embeddings = self.receiver_model({
            column: features[column] for column in categorical_columns_receiver
        })
        business_embeddings = self.business_model({
            **{column: features[column] for column in categorical_columns_business},
            'product_description': features['product_description'],
            'service_description': features['service_description']
        })
        print("Receiver embeddings shape:", receiver_embeddings.shape)
        print("Business embeddings shape:", business_embeddings.shape)
        return self.task(receiver_embeddings, business_embeddings)

# Initialize the receiver and business models
receiver_tower = ReceiverModel(categorical_encoders_receiver)
business_tower = BusinessModel(categorical_encoders_business, product_descriptions_encoded, service_descriptions_encoded)

# Define the retrieval task
# Note: candidates_dataset should contain all possible businesses to recommend,
# and it should be batched appropriately.
candidates_dataset = tf.data.Dataset.from_tensor_slices({
    "awarding_agency_name": dataframe["awarding_agency_name"],
    "client_office_name": dataframe["client_office_name"],
    "location": dataframe["location"],
    "award_type": dataframe["award_type"],
    "type_of_business": dataframe["type_of_business"],
    "product_description": product_descriptions_encoded,  # assuming this is already a tensor
    "service_description": service_descriptions_encoded   # assuming this is already a tensor
}).batch(128)

# Here we map our business model which will transform our business data into embeddings
# The candidates are being mapped through the business model to get their embeddings
candidates = candidates_dataset.map(lambda x: business_tower({
    "awarding_agency_name": x["awarding_agency_name"],
    "client_office_name": x["client_office_name"],
    "location": x["location"],
    "award_type": x["award_type"],
    "type_of_business": x["type_of_business"],
    "product_description": x["product_description"],
    "service_description": x["service_description"]
}))

task = tfrs.tasks.Retrieval(
    metrics=tfrs.metrics.FactorizedTopK(candidates=candidates)
)

# Create a retrieval model
model = RecommenderModel(receiver_tower, business_tower, task)

# Compile the model
model.compile(optimizer=tf.keras.optimizers.Adagrad(0.5))

# Prepare the dataset for training, which should include both business and receiver features
# Make sure to batch the dataset as needed
train_dataset = tf.data.Dataset.from_tensor_slices({
    "reciever_country_name": dataframe["reciever_country_name"],
    "reciever_state_name": dataframe["reciever_state_name"],
    # ... include all the other receiver features
    "awarding_agency_name": dataframe["awarding_agency_name"],
    "client_office_name": dataframe["client_office_name"],
    "location": dataframe["location"],
    "award_type": dataframe["award_type"],
    "type_of_business": dataframe["type_of_business"],
    "product_description": product_descriptions_encoded,  # assuming this is already a tensor
    "service_description": service_descriptions_encoded   # assuming this is already a tensor
}).batch(4096)

# Train for 3 epochs
model.fit(train_dataset, epochs=3)